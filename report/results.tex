
% TODO Fix subset of data w. four classes
\begin{tabular}{ c | c | c | c | }
	 WK  & Precision & Recall & F1   \\ \hline	
	 acq &  0.974 (0.843) & 0.930 (0.768) & 0.951 (0.802) \\ \hline
	 earn &   0.978 (0.989)& 0.972 (0.867)& 0.976 (0.925)  \\ \hline
	 corn &   0.992 (0.833) & 0.867 (0.710) &  0.923 (0.762) \\ \hline
	 crude &   0.946 (0.910) & 0.957 (0.907) &  0.948 (0.904) \\ \hline
	
\end{tabular}
\captionof{table}{Running Word Kernel ten times and averaging the result. Numbers in parenthesis is the reference value.}

\begin{tabular}{ c | c | c | c | c | }
	NGK & k & Precision & Recall & F1   \\ \hline	
	 & 3 & 0.96 & 0.88 & 0.92     \\ 
	acq & 4 & 0.90 & 0.89 &  0.89    \\
	 & 5 & 0.97 & 0.86 & 0.92     \\ \hline
	 & 3 & 0.97 & 0.93 &  0.95    \\ 
	earn & 4 & 0.99 & 0.93 &  0.96    \\ 
	 & 5 & 0.99 & 0.89 &  0.93    \\ \hline
	 & 3 & 1 & 0.87 & 0.93     \\ 
	corn & 4 & 1 & 0.64 & 0.78     \\ 
	 & 5 & 1 & 0.44 &  0.61    \\ \hline
	 & 3 & 0.90 & 0.90 &  0.90    \\ 
	crude & 4 & 0.92 & 0.86 & 0.89     \\ 
	 & 5 & 1 & 0.73 &  0.84    \\ \hline
\end{tabular}
\captionof{table}{Subset of the NGK runs for different length N. We can clearly see that NGK performs well for small N, but considerably worse for larger N (see appendix).}
\begin{tabular}{ c | c | c | c | c | }
	SSK & k, $ \lambda = 0.5 $ & Precision & Recall & F1   \\ \hline	
	& 3 & 0.96 & 0.88 & 0.92     \\ 
	acq & 4 & 0.90 & 0.89 &  0.89    \\
	& 5 & 0.97 & 0.86 & 0.92     \\ \hline
	& 3 & 0.97 & 0.93 &  0.95    \\ 
	earn & 4 & 0.99 & 0.93 &  0.96    \\ 
	& 5 & 0.99 & 0.89 &  0.93    \\ \hline
	& 3 & 1 & 0.87 & 0.93     \\ 
	corn & 4 & 1 & 0.64 & 0.78     \\ 
	& 5 & 1 & 0.44 &  0.61    \\ \hline
	& 3 & 0.90 & 0.90 &  0.90    \\ 
	crude & 4 & 0.92 & 0.86 & 0.89     \\ 
	& 5 & 1 & 0.73 &  0.84    \\ \hline
\end{tabular}
\captionof{table}{String Subsequence Kernel for different length k. Like it's algorithmic cousin the NGK, it performs well for relative small k, but less well for larger k (again, see appendix for all data).}

\begin{tabular}{ c | c | c | c | c | }
	SSK & $ \lambda  $, k = 5& Precision & Recall & F1   \\ \hline	
	& 0.05 & 1 & 0.92 & 0.96     \\ 
	acq & 0.1 & 1& 1 &  1    \\
	& 0.5 & 0.89 & 1 & 0.94     \\ \hline
	& 0.05 & 1 & 0.98 &  0.99    \\ 
	earn & 0.1 & 0.98 & 1 &  0.99    \\ 
	& 0.5 & 1 & 0.90 &  0.95    \\ \hline
	& 0.05 & 1 & 0.87 & 0.93     \\ 
	corn & 0.1 & 1 & 0.87 & 0.93     \\ 
	& 0.5 & 0.94 & 1 &  0.97   \\ \hline
	& 0.05 & 0.90 & 0.75 &  0.82    \\ 
	crude & 0.1 & 1 & 0.91 & 0.95     \\ 
	& 0.5 & 1 & 0.70 &  0.82    \\ \hline
\end{tabular}
\captionof{table}{Varying $ \lambda $ shows that SSK is not that sensitive to values of $ \lambda $. Generally we can see that unless you choose more extreme values, the SSK performs well. }

% TODO Alignment of S vectors
\begin{figure}
	\centering
	\begin{equation}
		\begin{tabular}{c c}
		\null \hfill
			\subfloat[]{\includegraphics[height = 5cm]{../plots/Alignment_scores.pdf}} \hfill & 
			\subfloat[]{\includegraphics[height = 4.4cm]{../plots/Lodhi_alignment_score.png}} \hfill \null
		\end{tabular}
	\end{equation}
	\captionof{figure}{left is ours, right's Lodhi's. Padding is f*cked.}
\end{figure}

% TODO Approximation check (table 8 in report)
\begin{tabular}{ c | c | c | }
	& s = 1000 & s = 3000   \\ \hline
	acq & 0.96 (0.88)& 0.97 (0.85)\\ \hline
	earn & 0.98 (0.97) & 0.98  (0.97) \\ \hline
	ship & 0.43 (0.10) & 0.63  (0.53) \\ \hline
	corn & 0.84 (0.15) & 0.89 (0.65) \\ \hline
\end{tabular}
\captionof{table}{F1 scores for approximate kernel validation. k = 5 and $ \lambda = 0.5 $. Lodhi's results in parenthesis. }

% 1130


% TODO top 10 classes results
\begin{tabular}{ c | c | c | c | c | c | c | c |}
	& WK & NGK & NGK  & NGK  & SSK & SSK& SSK \\ 
	&  & n = 3& n = 4 & n = 5 & n = 3& n = 4 & n = 5 \\ \hline
	earn & 0.98 & 0.98 &  0.98&  0.98 & 0.98 & 0.98 & 0.98 \\ \hline
	acq & 0.97 & 0.95 &  0.95 &  0.96 & 0.95 & 0.95 & 0.95 \\ \hline
	money-fx & 0.79 & 0.77 &  0.79 & 0.77 & 0.77 & 0.8 & 0.78 \\ \hline
	grain & 0.92 & 0.81 &  0.83& 0.82 & 0.84 & 0.86 & 0.8 \\ \hline
	crude & 0.87 & 0.84 &  0.85 & 0.8 & 0.82 & 0.79 & 0.73 \\ \hline
	trade & 0.8 & 0.73 &  0.77 & 0.77 & 0.72 & 0.79 & 0.77 \\ \hline
	interest & 0.8 & 0.72 &  0.73 & 0.75 & 0.79 & 0.8 & 0.77 \\ \hline
	ship & 0.78 & 0.66 &  0.55 & 0.47 & 0.69 & 0.5 & 0.34 \\ \hline
	wheat & 0.79 & 0.86 &  0.84 & 0.8 & 0.8 & 0.8 & 0.76 \\ \hline
	corn & 0.86 & 0.73 &  0.85 & 0.65 & 0.78 & 0.72 & 0.6 \\ \hline	
\end{tabular}
\captionof{table}{Lodhi's top ten performing classes for the full dataset with an approximating kernel.}