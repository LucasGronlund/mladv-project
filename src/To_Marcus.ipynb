{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "#import FAST_RECURSION_KERNEL as frkernel  #This is the kernel that marcus is working on.\n",
    "# import kernel as k\n",
    "import subprocess\n",
    "import io\n",
    "import fetch_data as fd\n",
    "import MostFrequentFeatures as mff\n",
    "import svm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _k_prime(s,t,n,l):\n",
    "\n",
    "    #-------------------------------------------------------------------------------------#\n",
    "    # Basically what's happening here is that we are succesively looping through both of  #\n",
    "    # the strings and updating the kernel matrix accordingly while refering to previously #\n",
    "    # computed values. This will give us time complexity O(n|s||t|) in the end.           #\n",
    "    #-------------------------------------------------------------------------------------#\n",
    "    \n",
    "    \n",
    "    #Variables:\n",
    "    #\n",
    "    #s is a string\n",
    "    #t is a string\n",
    "    #n is the length of the substring\n",
    "    #l is the lambda value\n",
    "    #kp is refering to k'\n",
    "    #kpp is refering to k'' \n",
    "    \n",
    "    #start by creating the empty matrices.\n",
    "    kp = np.zeros([n,len(s)+1,len(t)+1]);\n",
    "    kpp = np.zeros([n,len(s)+1,len(t)+1]);\n",
    "    \n",
    "    #initialize\n",
    "    kp[0][:][:] = 1;\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        for j in range(i,len(s)):\n",
    "            for k in range(i,len(t)+1):\n",
    "\n",
    "                #check whether 'x occurs in u' as described in the paper\n",
    "                if(s[j-1]!=t[k-1]):\n",
    "                    kpp[i][j][k]=l*kpp[i][j][k-1];\n",
    "                #if not, do the other calcs.http://localhost:8888/notebooks/To_Marcus.ipynb#\n",
    "                else:\n",
    "                    kpp[i][j][k]=l*(kpp[i][j][k-1]+l*kp[i-1][j-1][k-1]);\n",
    "                \n",
    "                #finally calculate kp\n",
    "                kp[i][j][k-1]=l*kp[i][j-1][k-1]+kpp[i][j][k-1];\n",
    "                \n",
    "    return kp;\n",
    "\n",
    "\n",
    "def _k(s,t,n,l,kp):\n",
    "    \n",
    "    #--------------------------------------------------#\n",
    "    # This takes in an already computed k_prime kernel #\n",
    "    # and calculates the overall kernel as per the     #\n",
    "    # paper. The last part of Def. 2                   #\n",
    "    #--------------------------------------------------#\n",
    "\n",
    "    #Variables:\n",
    "    #\n",
    "    #s is a string\n",
    "    #t is a string\n",
    "    #n is the length of the substring\n",
    "    #l is the lambda value\n",
    "    #kp is refering to k'\n",
    "    #ksum is refering to the kernel value.\n",
    "    \n",
    "    ksum = 0;\n",
    "    \n",
    "    #Loop over all values in the computed k_prime matrix and \n",
    "    #pick out the values where x = j, as mentioned in the paper.\n",
    "    #\n",
    "    #There is no recursion necessary here since we already did it\n",
    "    #when computing k_prime, the last 'layer' of k_prime\n",
    "    #contains all the necessary values.\n",
    "\n",
    "    for i in range(kp.shape[1]-1):\n",
    "        for j in range(kp.shape[2]-1):\n",
    "            if s[i] == t[j] : \n",
    "                ksum += kp[n-1][i][j];\n",
    "                \n",
    "    return l**2*ksum;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximative_kernel(x,z,s,n,l):\n",
    "    N = len(x)\n",
    "    kss = [ _k(i,i,n,l,_k_prime(i,i,n,l)) for i in tqdm(s)]\n",
    "    kxx = [ _k(i,i,n,l,_k_prime(i,i,n,l)) for i in tqdm(x)]\n",
    "    kxs = kernelValuesListChptr6(x,s,n,l)    \n",
    "    if hash(tuple(x)) == hash(tuple(z)):\n",
    "        K = np.identity(N)\n",
    "        print('Square kernel matrix generated')\n",
    "        for i,xx in enumerate(x):\n",
    "            for j in range(i+1,N):\n",
    "                for k,ss in enumerate(s):\n",
    "                    k = (kxs[i][k]*kxs[j][k])/(kss[k]*sqrt(kxx[j]*kxx[i]))\n",
    "                    K[i,j] += k\n",
    "                    K[j,i] += k\n",
    "        return K   \n",
    "\n",
    "    K = np.zeros([N,len(z)])\n",
    "    kzz = [ _k(i,i,n,l,_k_prime(i,i,n,l)) for i in z]\n",
    "    kxz = kernelValuesListChptr6(z,s,n,l)\n",
    "    for i,xx in enumerate(tqdm(x)):\n",
    "        for j,zz in enumerate(z):\n",
    "            for k,ss in enumerate(s):\n",
    "                K[i,j] += (kxs[i][k]*kxz[j][k])/(kss[k]*sqrt(kzz[j]*kxx[i]))\n",
    "    return K\n",
    "\n",
    "def kernelValuesListChptr6(x,s,n,l):\n",
    "    Kxs = np.zeros([len(x),len(s)]);\n",
    "    for i in tqdm(range(len(x))):\n",
    "        for j in range(len(s)):\n",
    "            Kxs[i][j]=_k(x[i],s[j],n,l,_k_prime(x[i],s[j],n,l))\n",
    "    return Kxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "cwd = os.getcwd()+'/../data/clean_data';\n",
    "kerns = os.path.join(cwd,'trainData.npy')\n",
    "trainData = np.load(kerns)\n",
    "\n",
    "kerns = os.path.join(cwd,'testData.npy')\n",
    "testData = np.load(kerns)\n",
    "\n",
    "kerns = os.path.join(cwd,'trainLabels.npy')\n",
    "trainLabels = np.load(kerns)\n",
    "\n",
    "kerns = os.path.join(cwd,'testLabels.npy')\n",
    "# testLabels = np.load(kerns)\n",
    "\n",
    "# categories = ['earn','crude']\n",
    "# numberOfTraining = [10,10]\n",
    "# numberOfTesting = [7,2]\n",
    "\n",
    "\n",
    "# trainData,trainLabels, testData,testLabel = fd.loadData(categories,numberOfTraining,numberOfTesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set params\n",
    "n = 3;  #how long the substrings should be.\n",
    "lmda = 0.5; #The penalty (weight) paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## OBS OBS OBS OBS OBS ################\n",
    "# Det Ã¤r oklart om denna kod fungerar korrekt!!!\n",
    "\n",
    "def marcus_mostFrequentFeatures(dataset, k, numbTop,prints = False):\n",
    "    the_long_string = ''\n",
    "    list_of_features = []\n",
    "    for i in dataset:\n",
    "        the_long_string += i\n",
    "    the_len = len(the_long_string)\n",
    "    for i in tqdm(range(the_len-k+1)):\n",
    "        curr_str = the_long_string[i:i+n]\n",
    "        if not curr_str in list_of_features:\n",
    "            list_of_features.append(curr_str)\n",
    "    scores = np.zeros(len(list_of_features))\n",
    "    for index, feature in tqdm(enumerate(list_of_features)):\n",
    "        scores[index] += the_long_string.count(feature)\n",
    "    topFeatures = []\n",
    "    topFeatureScores =  []\n",
    "    scores = scores.argsort()[-len(scores):][::-1]\n",
    "    features = np.array(list_of_features)\n",
    "    topFeatures = features[scores][:numbTop]\n",
    "    topFeatureScores = scores[:numbTop]\n",
    "    return topFeatures, topFeatureScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the S most commonly occuring n-grams\n",
    "\n",
    "S = 500;\n",
    "\n",
    "topFeatures, topFeatureScores = mff.mostFrequentFeatures(trainData,n,S)\n",
    "topFeatures2, topFeatureScores2 = marcus_mostFrequentFeatures(trainData,n,S)\n",
    "\n",
    "\n",
    "test_list_1 = topFeatures\n",
    "test_list_2 = topFeatures2\n",
    "\n",
    "len(test_list_1)\n",
    "a = 0\n",
    "for i in test_list_1:\n",
    "    if i in test_list_2:\n",
    "        a += 1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute kernel using these to approximate. \n",
    "\n",
    "Ktrain_approx = approximative_kernel(trainData,trainData,topFeatures,n,lmda)\n",
    "\n",
    "Ktest_approx = approximative_kernel(trainData,testData,topFeatures,n,lmda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the fast_apprximative_kernel\n",
    "test = subprocess.Popen([\"g++\",\"fast_approximative_kernel.cpp\",\"-o\",\"fast_approximative_kernel.out\"], stdout=subprocess.PIPE)\n",
    "output_compile = test.communicate()[0]\n",
    "# print(output_compile.decode('ascii'))\n",
    "def parseMatrix(matrix):\n",
    "    num_rows = int(matrix[0])\n",
    "    num_cols = int(matrix[1])\n",
    "    K = np.zeros([num_rows,num_cols])\n",
    "    counter = 2\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            K[i,j] = float(matrix[counter])\n",
    "            counter = counter + 1\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fast_recursive_kernel\n",
    "# x = trainData\n",
    "# z = trainData\n",
    "# s = topFeatures\n",
    "# n = 3;  #how long the substrings should be.\n",
    "# lmda = 0.5; #The penalty (weight) paramter\n",
    "\n",
    "def marcus_approximative_kernel(x,z,s,n,lmda):\n",
    "    the_strings = b''\n",
    "    if hash(tuple(x)) == hash(tuple(z)):\n",
    "        equal_hash = b'1 '\n",
    "    else:\n",
    "        equal_hash = b'0 '\n",
    "    the_args = bytes(str(len(x)),'ascii')+ b' ' + bytes(str(len(z)),'ascii')+ b' ' + bytes(str(len(s)),'ascii')+ b' '\n",
    "    for i in x:\n",
    "        the_strings = the_strings + bytes(i,'ascii')\n",
    "        the_args = the_args + bytes(str(len(i)),'ascii') + b' '\n",
    "    for i in z:\n",
    "        the_strings = the_strings + bytes(i,'ascii')\n",
    "        the_args = the_args + bytes(str(len(i)),'ascii') + b' '\n",
    "    for i in s:\n",
    "        the_strings = the_strings + bytes(i,'ascii')\n",
    "        the_args = the_args + bytes(str(len(i)),'ascii') + b' '\n",
    "    the_args = the_args + bytes(str(n), 'ascii')+ b' ' + bytes(str(lmda), 'ascii')\n",
    "    fast_kernel = subprocess.Popen([\"./fast_approximative_kernel.out\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    output_test = fast_kernel.communicate(input=equal_hash+the_args+the_strings)[0]\n",
    "#     print(output_test.decode('utf-8'))\n",
    "    output_test_list = output_test.decode('utf-8').split()\n",
    "    K = parseMatrix(output_test_list)\n",
    "    return K\n",
    "\n",
    "K_approx_train_marcus = marcus_approximative_kernel(trainData,trainData,topFeatures,n,lmda)\n",
    "K_approx_test_marcus = marcus_approximative_kernel(trainData,testData,topFeatures,n,lmda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ktest_approx-K_approx_test_marcus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
