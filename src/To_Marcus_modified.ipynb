{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "#import FAST_RECURSION_KERNEL as frkernel  #This is the kernel that marcus is working on.\n",
    "# import kernel as k\n",
    "import subprocess\n",
    "import io\n",
    "import fetch_data as fd\n",
    "import MostFrequentFeatures as mff\n",
    "import svm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _k_prime(s,t,n,l):\n",
    "\n",
    "    #-------------------------------------------------------------------------------------#\n",
    "    # Basically what's happening here is that we are succesively looping through both of  #\n",
    "    # the strings and updating the kernel matrix accordingly while refering to previously #\n",
    "    # computed values. This will give us time complexity O(n|s||t|) in the end.           #\n",
    "    #-------------------------------------------------------------------------------------#\n",
    "    \n",
    "    \n",
    "    #Variables:\n",
    "    #\n",
    "    #s is a string\n",
    "    #t is a string\n",
    "    #n is the length of the substring\n",
    "    #l is the lambda value\n",
    "    #kp is refering to k'\n",
    "    #kpp is refering to k'' \n",
    "    \n",
    "    #start by creating the empty matrices.\n",
    "    kp = np.zeros([n,len(s)+1,len(t)+1]);\n",
    "    kpp = np.zeros([n,len(s)+1,len(t)+1]);\n",
    "    \n",
    "    #initialize\n",
    "    kp[0][:][:] = 1;\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        for j in range(i,len(s)):\n",
    "            for k in range(i,len(t)+1):\n",
    "\n",
    "                #check whether 'x occurs in u' as described in the paper\n",
    "                if(s[j-1]!=t[k-1]):\n",
    "                    kpp[i][j][k]=l*kpp[i][j][k-1];\n",
    "                #if not, do the other calcs.http://localhost:8888/notebooks/To_Marcus.ipynb#\n",
    "                else:\n",
    "                    kpp[i][j][k]=l*(kpp[i][j][k-1]+l*kp[i-1][j-1][k-1]);\n",
    "                \n",
    "                #finally calculate kp\n",
    "                kp[i][j][k-1]=l*kp[i][j-1][k-1]+kpp[i][j][k-1];\n",
    "                \n",
    "    return kp;\n",
    "\n",
    "\n",
    "def _k(s,t,n,l,kp):\n",
    "    \n",
    "    #--------------------------------------------------#\n",
    "    # This takes in an already computed k_prime kernel #\n",
    "    # and calculates the overall kernel as per the     #\n",
    "    # paper. The last part of Def. 2                   #\n",
    "    #--------------------------------------------------#\n",
    "\n",
    "    #Variables:\n",
    "    #\n",
    "    #s is a string\n",
    "    #t is a string\n",
    "    #n is the length of the substring\n",
    "    #l is the lambda value\n",
    "    #kp is refering to k'\n",
    "    #ksum is refering to the kernel value.\n",
    "    \n",
    "    ksum = 0;\n",
    "    \n",
    "    #Loop over all values in the computed k_prime matrix and \n",
    "    #pick out the values where x = j, as mentioned in the paper.\n",
    "    #\n",
    "    #There is no recursion necessary here since we already did it\n",
    "    #when computing k_prime, the last 'layer' of k_prime\n",
    "    #contains all the necessary values.\n",
    "\n",
    "    for i in range(kp.shape[1]-1):\n",
    "        for j in range(kp.shape[2]-1):\n",
    "            if s[i] == t[j] : \n",
    "                ksum += kp[n-1][i][j];\n",
    "                \n",
    "    return l**2*ksum;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximative_kernel(x,z,s,n,l):\n",
    "    N = len(x)\n",
    "    kss = [ _k(i,i,n,l,_k_prime(i,i,n,l)) for i in tqdm(s)]\n",
    "    kxx = [ _k(i,i,n,l,_k_prime(i,i,n,l)) for i in tqdm(x)]\n",
    "    kxs = kernelValuesListChptr6(x,s,n,l)    \n",
    "    if hash(tuple(x)) == hash(tuple(z)):\n",
    "        K = np.identity(N)\n",
    "        print('Square kernel matrix generated')\n",
    "        for i,xx in enumerate(x):\n",
    "            for j in range(i+1,N):\n",
    "                for k,ss in enumerate(s):\n",
    "                    k = (kxs[i][k]*kxs[j][k])/(kss[k]*sqrt(kxx[j]*kxx[i]))\n",
    "                    K[i,j] += k\n",
    "                    K[j,i] += k\n",
    "        return K   \n",
    "\n",
    "    K = np.zeros([N,len(z)])\n",
    "    kzz = [ _k(i,i,n,l,_k_prime(i,i,n,l)) for i in z]\n",
    "    kxz = kernelValuesListChptr6(z,s,n,l)\n",
    "    for i,xx in enumerate(tqdm(x)):\n",
    "        for j,zz in enumerate(z):\n",
    "            for k,ss in enumerate(s):\n",
    "                K[i,j] += (kxs[i][k]*kxz[j][k])/(kss[k]*sqrt(kzz[j]*kxx[i]))\n",
    "    return K\n",
    "\n",
    "def kernelValuesListChptr6(x,s,n,l):\n",
    "    Kxs = np.zeros([len(x),len(s)]);\n",
    "    for i in tqdm(range(len(x))):\n",
    "        for j in range(len(s)):\n",
    "            Kxs[i][j]=_k(x[i],s[j],n,l,_k_prime(x[i],s[j],n,l))\n",
    "    return Kxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "# cwd = os.getcwd()+'/../data/clean_data';\n",
    "# kerns = os.path.join(cwd,'trainData.npy')\n",
    "# trainData = np.load(kerns)\n",
    "\n",
    "# kerns = os.path.join(cwd,'testData.npy')\n",
    "# testData = np.load(kerns)\n",
    "\n",
    "# kerns = os.path.join(cwd,'trainLabels.npy')\n",
    "# trainLabels = np.load(kerns)\n",
    "\n",
    "# kerns = os.path.join(cwd,'testLabels.npy')\n",
    "# testLabels = np.load(kerns)\n",
    "\n",
    "categories = ['earn','crude']\n",
    "numberOfTraining = [10,10]\n",
    "numberOfTesting = [7,2]\n",
    "\n",
    "\n",
    "trainData,trainLabels, testData,testLabel = fd.loadData(categories,numberOfTraining,numberOfTesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set params\n",
    "n = 4;  #how long the substrings should be.\n",
    "lmda = 0.5; #The penalty (weight) paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## OBS OBS OBS OBS OBS ################\n",
    "# Det är oklart om denna kod fungerar korrekt!!!\n",
    "\n",
    "def marcus_mostFrequentFeatures(dataset, k, numbTop,prints = False):\n",
    "#     the_long_string = ''\n",
    "    list_of_features = []\n",
    "    for i in tqdm(dataset):\n",
    "#         the_long_string += i\n",
    "        the_len = len(i)\n",
    "        for j in range(the_len-k+1):\n",
    "            curr_str = i[j:j+n]\n",
    "            if not curr_str in list_of_features:\n",
    "                list_of_features.append(curr_str)\n",
    "    scores = np.zeros(len(list_of_features))\n",
    "    for index, feature in tqdm(enumerate(list_of_features)):\n",
    "        for i in dataset:\n",
    "            scores[index] += i.count(feature)\n",
    "    topFeatures = []\n",
    "    topFeatureScores =  []\n",
    "    scores = scores.argsort()[-len(scores):][::-1]\n",
    "    features = np.array(list_of_features)\n",
    "    topFeatures = features[scores][:numbTop]\n",
    "    topFeatureScores = scores[:numbTop]\n",
    "    return topFeatures, topFeatureScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 47.78it/s] \n",
      "4771it [00:00, 34386.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#Find the S most commonly occuring n-grams\n",
    "\n",
    "S = 500;\n",
    "\n",
    "# topFeatures, topFeatureScores = mff.mostFrequentFeatures(trainData,n,S)\n",
    "topFeatures, topFeatureScores = marcus_mostFrequentFeatures(trainData,n,S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stri\n",
      "ed l\n",
      "498\n"
     ]
    }
   ],
   "source": [
    "test_list_2 = topFeatures\n",
    "test_list_1 = topFeatures2\n",
    "len(test_list_1)\n",
    "a = 0\n",
    "for i in test_list_1:\n",
    "    if i in test_list_2:\n",
    "        a += 1\n",
    "    else:\n",
    "        print(i)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'approximative_kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3d8df3792757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Compute kernel using these to approximate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mKtrain_approx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapproximative_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopFeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlmda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mKtest_approx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapproximative_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopFeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlmda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'approximative_kernel' is not defined"
     ]
    }
   ],
   "source": [
    "#Compute kernel using these to approximate. \n",
    "\n",
    "Ktrain_approx = approximative_kernel(trainData,trainData,topFeatures,n,lmda)\n",
    "\n",
    "Ktest_approx = approximative_kernel(trainData,testData,topFeatures,n,lmda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the fast_apprximative_kernel\n",
    "test = subprocess.Popen([\"g++\",\"fast_approximative_kernel_modified.cpp\",\"-o\",\"fast_approximative_kernel_modified.out\"], stdout=subprocess.PIPE)\n",
    "output_compile = test.communicate()[0]\n",
    "# print(output_compile.decode('ascii'))\n",
    "def parseMatrix(matrix):\n",
    "    num_rows = int(matrix[0])\n",
    "    num_cols = int(matrix[1])\n",
    "    K = np.zeros([num_rows,num_cols])\n",
    "    counter = 2\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            K[i,j] = float(matrix[counter])\n",
    "            counter = counter + 1\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fast_recursive_kernel\n",
    "# x = trainData\n",
    "# z = trainData\n",
    "# s = topFeatures\n",
    "# n = 3;  #how long the substrings should be.\n",
    "# lmda = 0.5; #The penalty (weight) paramter\n",
    "\n",
    "\n",
    "def marcus_approximative_kernel_modified(x,z,s,n,lmda,cutoff = 1000):\n",
    "    the_strings = b''\n",
    "    if hash(tuple(x)) == hash(tuple(z)):\n",
    "        equal_hash = b'1 '\n",
    "    else:\n",
    "        equal_hash = b'0 '\n",
    "    the_args = bytes(str(len(x)),'ascii')+ b' ' + bytes(str(len(z)),'ascii')+ b' ' + bytes(str(len(s)),'ascii')+ b' '\n",
    "    for i in x:\n",
    "        the_strings = the_strings + bytes(i,'ascii')\n",
    "        the_args = the_args + bytes(str(len(i)),'ascii') + b' '\n",
    "    for i in z:\n",
    "        the_strings = the_strings + bytes(i,'ascii')\n",
    "        the_args = the_args + bytes(str(len(i)),'ascii') + b' '\n",
    "    for i in s:\n",
    "        the_strings = the_strings + bytes(i,'ascii')\n",
    "        the_args = the_args + bytes(str(len(i)),'ascii') + b' '\n",
    "    the_args = the_args + bytes(str(n), 'ascii')+ b' ' + bytes(str(lmda), 'ascii') + b' ' + bytes(str(cutoff), 'ascii')\n",
    "    fast_kernel = subprocess.Popen([\"./fast_approximative_kernel.out\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    output_test = fast_kernel.communicate(input=equal_hash+the_args+the_strings)[0]\n",
    "#     print(output_test.decode('utf-8'))\n",
    "    output_test_list = output_test.decode('utf-8').split()\n",
    "    K = parseMatrix(output_test_list)\n",
    "    return K\n",
    "\n",
    "K_approx_train_marcus = marcus_approximative_kernel_modified(trainData,trainData,topFeatures,n,lmda)\n",
    "# K_approx_test_marcus = marcus_approximative_kernel_modified(trainData,testData,topFeatures,n,lmda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.01182621,  0.0074245 ,  0.00633539,  0.01066224,\n",
       "         0.00786842,  0.01060007,  0.01195837,  0.00923428,  0.00879095,\n",
       "         0.01768827,  0.01059191,  0.01088104,  0.01374478,  0.00853126,\n",
       "         0.01862107,  0.02354321,  0.02091528,  0.01631865,  0.02035403],\n",
       "       [ 0.01182621,  1.        ,  0.03027279,  0.0271145 ,  0.03133933,\n",
       "         0.03174243,  0.02904974,  0.02082363,  0.0421002 ,  0.0343287 ,\n",
       "         0.01661011,  0.01897266,  0.00304298,  0.00497752,  0.01509841,\n",
       "         0.00611871,  0.00834498,  0.00765833,  0.00576147,  0.00577639],\n",
       "       [ 0.0074245 ,  0.03027279,  1.        ,  0.03263893,  0.04910309,\n",
       "         0.03896058,  0.04422503,  0.04530088,  0.0646792 ,  0.0448852 ,\n",
       "         0.00743573,  0.01841847,  0.00445588,  0.00458549,  0.00490034,\n",
       "         0.0069824 ,  0.00956733,  0.01106319,  0.00812808,  0.00817854],\n",
       "       [ 0.00633539,  0.0271145 ,  0.03263893,  1.        ,  0.03453381,\n",
       "         0.03237325,  0.03740296,  0.03139265,  0.04801817,  0.04549282,\n",
       "         0.01398851,  0.02361668,  0.00847152,  0.00453427,  0.00863253,\n",
       "         0.01384535,  0.01371433,  0.01686105,  0.00811456,  0.00555835],\n",
       "       [ 0.01066224,  0.03133933,  0.04910309,  0.03453381,  1.        ,\n",
       "         0.04119265,  0.04499611,  0.05450679,  0.05779799,  0.04170641,\n",
       "         0.01067262,  0.02057738,  0.00589263,  0.00398155,  0.00548424,\n",
       "         0.00939878,  0.01318874,  0.0170944 ,  0.00872049,  0.01260587],\n",
       "       [ 0.00786842,  0.03174243,  0.03896058,  0.03237325,  0.04119265,\n",
       "         1.        ,  0.03226138,  0.02130787,  0.04630006,  0.04108285,\n",
       "         0.00418643,  0.02060391,  0.00213182,  0.00441676,  0.00504405,\n",
       "         0.00501463,  0.0086828 ,  0.00237665,  0.00920284,  0.00465367],\n",
       "       [ 0.01060007,  0.02904974,  0.04422503,  0.03740296,  0.04499611,\n",
       "         0.03226138,  1.        ,  0.04906468,  0.0638426 ,  0.046035  ,\n",
       "         0.01645311,  0.02216566,  0.00820612,  0.00516838,  0.00849599,\n",
       "         0.01501569,  0.01599981,  0.02330954,  0.01025044,  0.01190158],\n",
       "       [ 0.01195837,  0.02082363,  0.04530088,  0.03139265,  0.05450679,\n",
       "         0.02130787,  0.04906468,  1.        ,  0.06528582,  0.03837288,\n",
       "         0.01922689,  0.01616777,  0.01079604,  0.0070584 ,  0.01028551,\n",
       "         0.01877914,  0.02094055,  0.02893023,  0.01043437,  0.01808523],\n",
       "       [ 0.00923428,  0.0421002 ,  0.0646792 ,  0.04801817,  0.05779799,\n",
       "         0.04630006,  0.0638426 ,  0.06528582,  1.        ,  0.06341583,\n",
       "         0.00772852,  0.01863992,  0.00242434,  0.00406304,  0.00389616,\n",
       "         0.00507289,  0.00650015,  0.00630144,  0.00337048,  0.00501944],\n",
       "       [ 0.00879095,  0.0343287 ,  0.0448852 ,  0.04549282,  0.04170641,\n",
       "         0.04108285,  0.046035  ,  0.03837288,  0.06341583,  1.        ,\n",
       "         0.00826209,  0.02321973,  0.00670179,  0.00424352,  0.00570837,\n",
       "         0.00991035,  0.01148988,  0.015341  ,  0.00945269,  0.00446545],\n",
       "       [ 0.01768827,  0.01661011,  0.00743573,  0.01398851,  0.01067262,\n",
       "         0.00418643,  0.01645311,  0.01922689,  0.00772852,  0.00826209,\n",
       "         1.        ,  0.02353907,  0.0299248 ,  0.02510925,  0.0521437 ,\n",
       "         0.05360854,  0.0476323 ,  0.05085529,  0.03740541,  0.04056764],\n",
       "       [ 0.01059191,  0.01897266,  0.01841847,  0.02361668,  0.02057738,\n",
       "         0.02060391,  0.02216566,  0.01616777,  0.01863992,  0.02321973,\n",
       "         0.02353907,  1.        ,  0.01348866,  0.01423718,  0.01261198,\n",
       "         0.02632766,  0.02868458,  0.03063413,  0.02553116,  0.01883737],\n",
       "       [ 0.01088104,  0.00304298,  0.00445588,  0.00847152,  0.00589263,\n",
       "         0.00213182,  0.00820612,  0.01079604,  0.00242434,  0.00670179,\n",
       "         0.0299248 ,  0.01348866,  1.        ,  0.01673336,  0.02027054,\n",
       "         0.03076874,  0.03014531,  0.01884487,  0.02477849,  0.0263386 ],\n",
       "       [ 0.01374478,  0.00497752,  0.00458549,  0.00453427,  0.00398155,\n",
       "         0.00441676,  0.00516838,  0.0070584 ,  0.00406304,  0.00424352,\n",
       "         0.02510925,  0.01423718,  0.01673336,  1.        ,  0.0096613 ,\n",
       "         0.02405601,  0.02854637,  0.0207245 ,  0.02250792,  0.03049432],\n",
       "       [ 0.00853126,  0.01509841,  0.00490034,  0.00863253,  0.00548424,\n",
       "         0.00504405,  0.00849599,  0.01028551,  0.00389616,  0.00570837,\n",
       "         0.0521437 ,  0.01261198,  0.02027054,  0.0096613 ,  1.        ,\n",
       "         0.03141377,  0.02681629,  0.02464272,  0.0198912 ,  0.01937091],\n",
       "       [ 0.01862107,  0.00611871,  0.0069824 ,  0.01384535,  0.00939878,\n",
       "         0.00501463,  0.01501569,  0.01877914,  0.00507289,  0.00991035,\n",
       "         0.05360854,  0.02632766,  0.03076874,  0.02405601,  0.03141377,\n",
       "         1.        ,  0.04721658,  0.05292687,  0.03705917,  0.03959642],\n",
       "       [ 0.02354321,  0.00834498,  0.00956733,  0.01371433,  0.01318874,\n",
       "         0.0086828 ,  0.01599981,  0.02094055,  0.00650015,  0.01148988,\n",
       "         0.0476323 ,  0.02868458,  0.03014531,  0.02854637,  0.02681629,\n",
       "         0.04721658,  1.        ,  0.04756905,  0.04506829,  0.0430485 ],\n",
       "       [ 0.02091528,  0.00765833,  0.01106319,  0.01686105,  0.0170944 ,\n",
       "         0.00237665,  0.02330954,  0.02893023,  0.00630144,  0.015341  ,\n",
       "         0.05085529,  0.03063413,  0.01884487,  0.0207245 ,  0.02464272,\n",
       "         0.05292687,  0.04756905,  1.        ,  0.03785594,  0.03755392],\n",
       "       [ 0.01631865,  0.00576147,  0.00812808,  0.00811456,  0.00872049,\n",
       "         0.00920284,  0.01025044,  0.01043437,  0.00337048,  0.00945269,\n",
       "         0.03740541,  0.02553116,  0.02477849,  0.02250792,  0.0198912 ,\n",
       "         0.03705917,  0.04506829,  0.03785594,  1.        ,  0.03233149],\n",
       "       [ 0.02035403,  0.00577639,  0.00817854,  0.00555835,  0.01260587,\n",
       "         0.00465367,  0.01190158,  0.01808523,  0.00501944,  0.00446545,\n",
       "         0.04056764,  0.01883737,  0.0263386 ,  0.03049432,  0.01937091,\n",
       "         0.03959642,  0.0430485 ,  0.03755392,  0.03233149,  1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_approx_train_marcus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ktest_approx-K_approx_test_marcus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
