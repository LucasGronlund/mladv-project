{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "#import FAST_RECURSION_KERNEL as frkernel  #This is the kernel that marcus is working on.\n",
    "# import kernel as k\n",
    "import subprocess\n",
    "import io\n",
    "import fetch_data as fd\n",
    "import MostFrequentFeatures as mff\n",
    "import svm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _k_prime(s,t,n,l):\n",
    "\n",
    "    #-------------------------------------------------------------------------------------#\n",
    "    # Basically what's happening here is that we are succesively looping through both of  #\n",
    "    # the strings and updating the kernel matrix accordingly while refering to previously #\n",
    "    # computed values. This will give us time complexity O(n|s||t|) in the end.           #\n",
    "    #-------------------------------------------------------------------------------------#\n",
    "    \n",
    "    \n",
    "    #Variables:\n",
    "    #\n",
    "    #s is a string\n",
    "    #t is a string\n",
    "    #n is the length of the substring\n",
    "    #l is the lambda value\n",
    "    #kp is refering to k'\n",
    "    #kpp is refering to k'' \n",
    "    \n",
    "    #start by creating the empty matrices.\n",
    "    kp = np.zeros([n,len(s)+1,len(t)+1]);\n",
    "    kpp = np.zeros([n,len(s)+1,len(t)+1]);\n",
    "    \n",
    "    #initialize\n",
    "    kp[0][:][:] = 1;\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        for j in range(i,len(s)):\n",
    "            for k in range(i,len(t)+1):\n",
    "\n",
    "                #check whether 'x occurs in u' as described in the paper\n",
    "                if(s[j-1]!=t[k-1]):\n",
    "                    kpp[i][j][k]=l*kpp[i][j][k-1];\n",
    "                #if not, do the other calcs.http://localhost:8888/notebooks/To_Marcus.ipynb#\n",
    "                else:\n",
    "                    kpp[i][j][k]=l*(kpp[i][j][k-1]+l*kp[i-1][j-1][k-1]);\n",
    "                \n",
    "                #finally calculate kp\n",
    "                kp[i][j][k-1]=l*kp[i][j-1][k-1]+kpp[i][j][k-1];\n",
    "                \n",
    "    return kp;\n",
    "\n",
    "\n",
    "def _k(s,t,n,l,kp):\n",
    "    \n",
    "    #--------------------------------------------------#\n",
    "    # This takes in an already computed k_prime kernel #\n",
    "    # and calculates the overall kernel as per the     #\n",
    "    # paper. The last part of Def. 2                   #\n",
    "    #--------------------------------------------------#\n",
    "\n",
    "    #Variables:\n",
    "    #\n",
    "    #s is a string\n",
    "    #t is a string\n",
    "    #n is the length of the substring\n",
    "    #l is the lambda value\n",
    "    #kp is refering to k'\n",
    "    #ksum is refering to the kernel value.\n",
    "    \n",
    "    ksum = 0;\n",
    "    \n",
    "    #Loop over all values in the computed k_prime matrix and \n",
    "    #pick out the values where x = j, as mentioned in the paper.\n",
    "    #\n",
    "    #There is no recursion necessary here since we already did it\n",
    "    #when computing k_prime, the last 'layer' of k_prime\n",
    "    #contains all the necessary values.\n",
    "\n",
    "    for i in range(kp.shape[1]-1):\n",
    "        for j in range(kp.shape[2]-1):\n",
    "            if s[i] == t[j] : \n",
    "                ksum += kp[n-1][i][j];\n",
    "                \n",
    "    return l**2*ksum;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximative_kernel(x,z,s,n,l):\n",
    "    N = len(x)\n",
    "    kss = [ _k(i,i,n,l,_k_prime(i,i,n,l)) for i in tqdm(s)]\n",
    "    kxx = [ _k(i,i,n,l,_k_prime(i,i,n,l)) for i in tqdm(x)]\n",
    "    kxs = kernelValuesListChptr6(x,s,n,l)    \n",
    "    if hash(tuple(x)) == hash(tuple(z)):\n",
    "        K = np.identity(N)\n",
    "        print('Square kernel matrix generated')\n",
    "        for i,xx in enumerate(x):\n",
    "            for j in range(i+1,N):\n",
    "                for k,ss in enumerate(s):\n",
    "                    k = (kxs[i][k]*kxs[j][k])/(kss[k]*sqrt(kxx[j]*kxx[i]))\n",
    "                    K[i,j] += k\n",
    "                    K[j,i] += k\n",
    "        return K   \n",
    "\n",
    "    K = np.zeros([N,len(z)])\n",
    "    kzz = [ _k(i,i,n,l,_k_prime(i,i,n,l)) for i in z]\n",
    "    kxz = kernelValuesListChptr6(z,s,n,l)\n",
    "    for i,xx in enumerate(tqdm(x)):\n",
    "        for j,zz in enumerate(z):\n",
    "            for k,ss in enumerate(s):\n",
    "                K[i,j] += (kxs[i][k]*kxz[j][k])/(kss[k]*sqrt(kzz[j]*kxx[i]))\n",
    "    return K\n",
    "\n",
    "def kernelValuesListChptr6(x,s,n,l):\n",
    "    Kxs = np.zeros([len(x),len(s)]);\n",
    "    for i in tqdm(range(len(x))):\n",
    "        for j in range(len(s)):\n",
    "            Kxs[i][j]=_k(x[i],s[j],n,l,_k_prime(x[i],s[j],n,l))\n",
    "    return Kxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "# cwd = os.getcwd()+'/../data/clean_data';\n",
    "# kerns = os.path.join(cwd,'trainData.npy')\n",
    "# trainData = np.load(kerns)\n",
    "\n",
    "# kerns = os.path.join(cwd,'testData.npy')\n",
    "# testData = np.load(kerns)\n",
    "\n",
    "# kerns = os.path.join(cwd,'trainLabels.npy')\n",
    "# trainLabels = np.load(kerns)\n",
    "\n",
    "# kerns = os.path.join(cwd,'testLabels.npy')\n",
    "# testLabels = np.load(kerns)\n",
    "\n",
    "categories = ['earn','crude']\n",
    "numberOfTraining = [10,10]\n",
    "numberOfTesting = [7,2]\n",
    "\n",
    "\n",
    "trainData,trainLabels, testData,testLabel = fd.loadData(categories,numberOfTraining,numberOfTesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set params\n",
    "n = 4;  #how long the substrings should be.\n",
    "lmda = 0.5; #The penalty (weight) paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## OBS OBS OBS OBS OBS ################\n",
    "# Det är oklart om denna kod fungerar korrekt!!!\n",
    "\n",
    "def marcus_mostFrequentFeatures(dataset, k, numbTop,prints = False):\n",
    "#     the_long_string = ''\n",
    "    list_of_features = []\n",
    "    for i in tqdm(dataset):\n",
    "#         the_long_string += i\n",
    "        the_len = len(i)\n",
    "        for j in range(the_len-k+1):\n",
    "            curr_str = i[j:j+n]\n",
    "            if not curr_str in list_of_features:\n",
    "                list_of_features.append(curr_str)\n",
    "    scores = np.zeros(len(list_of_features))\n",
    "    for index, feature in tqdm(enumerate(list_of_features)):\n",
    "        for i in dataset:\n",
    "            scores[index] += i.count(feature)\n",
    "    topFeatures = []\n",
    "    topFeatureScores =  []\n",
    "    scores = scores.argsort()[-len(scores):][::-1]\n",
    "    features = np.array(list_of_features)\n",
    "    topFeatures = features[scores][:numbTop]\n",
    "    topFeatureScores = scores[:numbTop]\n",
    "    return topFeatures, topFeatureScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 45.42it/s] \n",
      "4816it [00:00, 38302.19it/s]\n"
     ]
    }
   ],
   "source": [
    "#Find the S most commonly occuring n-grams\n",
    "\n",
    "S = 500;\n",
    "\n",
    "# topFeatures, topFeatureScores = mff.mostFrequentFeatures(trainData,n,S)\n",
    "topFeatures, topFeatureScores = marcus_mostFrequentFeatures(trainData,n,S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stri\n",
      "ed l\n",
      "498\n"
     ]
    }
   ],
   "source": [
    "test_list_2 = topFeatures\n",
    "test_list_1 = topFeatures2\n",
    "len(test_list_1)\n",
    "a = 0\n",
    "for i in test_list_1:\n",
    "    if i in test_list_2:\n",
    "        a += 1\n",
    "    else:\n",
    "        print(i)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'approximative_kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3d8df3792757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Compute kernel using these to approximate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mKtrain_approx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapproximative_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopFeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlmda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mKtest_approx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapproximative_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopFeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlmda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'approximative_kernel' is not defined"
     ]
    }
   ],
   "source": [
    "#Compute kernel using these to approximate. \n",
    "\n",
    "Ktrain_approx = approximative_kernel(trainData,trainData,topFeatures,n,lmda)\n",
    "\n",
    "Ktest_approx = approximative_kernel(trainData,testData,topFeatures,n,lmda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the fast_apprximative_kernel\n",
    "test = subprocess.Popen([\"g++\",\"fast_approximative_kernel_modified.cpp\",\"-o\",\"fast_approximative_kernel_modified.out\"], stdout=subprocess.PIPE)\n",
    "output_compile = test.communicate()[0]\n",
    "# print(output_compile.decode('ascii'))\n",
    "def parseMatrix(matrix):\n",
    "    num_rows = int(matrix[0])\n",
    "    num_cols = int(matrix[1])\n",
    "    K = np.zeros([num_rows,num_cols])\n",
    "    counter = 2\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            K[i,j] = float(matrix[counter])\n",
    "            counter = counter + 1\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fast_recursive_kernel\n",
    "# x = trainData\n",
    "# z = trainData\n",
    "# s = topFeatures\n",
    "# n = 3;  #how long the substrings should be.\n",
    "# lmda = 0.5; #The penalty (weight) paramter\n",
    "\n",
    "\n",
    "def marcus_approximative_kernel_modified(x,z,s,n,lmda,cutoff = 1000):\n",
    "    the_strings = b''\n",
    "    if hash(tuple(x)) == hash(tuple(z)):\n",
    "        equal_hash = b'1 '\n",
    "    else:\n",
    "        equal_hash = b'0 '\n",
    "    the_args = bytes(str(len(x)),'ascii')+ b' ' + bytes(str(len(z)),'ascii')+ b' ' + bytes(str(len(s)),'ascii')+ b' '\n",
    "    for i in x:\n",
    "        the_strings = the_strings + bytes(i,'ascii')\n",
    "        the_args = the_args + bytes(str(len(i)),'ascii') + b' '\n",
    "    for i in z:\n",
    "        the_strings = the_strings + bytes(i,'ascii')\n",
    "        the_args = the_args + bytes(str(len(i)),'ascii') + b' '\n",
    "    for i in s:\n",
    "        the_strings = the_strings + bytes(i,'ascii')\n",
    "        the_args = the_args + bytes(str(len(i)),'ascii') + b' '\n",
    "    the_args = the_args + bytes(str(n), 'ascii')+ b' ' + bytes(str(lmda), 'ascii') + b' ' + bytes(str(cutoff), 'ascii')\n",
    "    fast_kernel = subprocess.Popen([\"./fast_approximative_kernel_modified.out\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    output_test = fast_kernel.communicate(input=equal_hash+the_args+the_strings)[0]\n",
    "#     print(output_test.decode('utf-8'))\n",
    "    output_test_list = output_test.decode('utf-8').split()\n",
    "    K = parseMatrix(output_test_list)\n",
    "    return K\n",
    "\n",
    "K_approx_train_marcus = marcus_approximative_kernel_modified(trainData,trainData,topFeatures,n,lmda)\n",
    "# K_approx_test_marcus = marcus_approximative_kernel_modified(trainData,testData,topFeatures,n,lmda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.08242561,  0.18219062,  0.20913314,  0.04293858,\n",
       "         0.07750887,  0.06437695,  0.27300627,  0.19712207,  0.14814499,\n",
       "         0.04310315,  0.02490148,  0.05439486,  0.06889738,  0.06388148,\n",
       "         0.01877461,  0.02597555,  0.0219039 ,  0.06752055,  0.03347359],\n",
       "       [ 0.08242561,  1.        ,  0.0618414 ,  0.07391461,  0.02655116,\n",
       "         0.03426447,  0.04039456,  0.09169236,  0.08148054,  0.05680781,\n",
       "         0.02671721,  0.01455872,  0.04785896,  0.06097451,  0.03309722,\n",
       "         0.01428176,  0.02627991,  0.01108572,  0.06384466,  0.02969764],\n",
       "       [ 0.18219062,  0.0618414 ,  1.        ,  0.10130453,  0.02103599,\n",
       "         0.09458186,  0.05547132,  0.18488424,  0.12692223,  0.08295083,\n",
       "         0.03124814,  0.0166606 ,  0.03857739,  0.05344801,  0.04079396,\n",
       "         0.02456069,  0.01359084,  0.01018007,  0.05364983,  0.02882414],\n",
       "       [ 0.20913314,  0.07391461,  0.10130453,  1.        ,  0.07637485,\n",
       "         0.0351465 ,  0.02828235,  0.15179788,  0.20367876,  0.24739306,\n",
       "         0.03297707,  0.01682242,  0.02720506,  0.03217407,  0.06347284,\n",
       "         0.01942563,  0.02692955,  0.00243989,  0.06743196,  0.02285335],\n",
       "       [ 0.04293858,  0.02655116,  0.02103599,  0.07637485,  1.        ,\n",
       "         0.07691933,  0.10776346,  0.02468015,  0.04485132,  0.10045778,\n",
       "         0.09823007,  0.04946993,  0.08848943,  0.15384311,  0.10963956,\n",
       "         0.06246077,  0.07112759,  0.0358517 ,  0.15929314,  0.10388119],\n",
       "       [ 0.07750887,  0.03426447,  0.09458186,  0.0351465 ,  0.07691933,\n",
       "         1.        ,  0.11169706,  0.07412287,  0.06668766,  0.0837951 ,\n",
       "         0.10636397,  0.06343312,  0.1082243 ,  0.14484943,  0.10965567,\n",
       "         0.06768116,  0.08578766,  0.0151023 ,  0.19085106,  0.0773172 ],\n",
       "       [ 0.06437695,  0.04039456,  0.05547132,  0.02828235,  0.10776346,\n",
       "         0.11169706,  1.        ,  0.06005769,  0.10391227,  0.06683532,\n",
       "         0.14164571,  0.06963382,  0.14240061,  0.22188297,  0.13441957,\n",
       "         0.10049245,  0.11859024,  0.04866638,  0.26657011,  0.12357917],\n",
       "       [ 0.27300627,  0.09169236,  0.18488424,  0.15179788,  0.02468015,\n",
       "         0.07412287,  0.06005769,  1.        ,  0.17890991,  0.09919662,\n",
       "         0.03971094,  0.0143491 ,  0.06419564,  0.05943078,  0.05464486,\n",
       "         0.03009905,  0.03833926,  0.01337146,  0.07392035,  0.03931251],\n",
       "       [ 0.19712207,  0.08148054,  0.12692223,  0.20367876,  0.04485132,\n",
       "         0.06668766,  0.10391227,  0.17890991,  1.        ,  0.14421508,\n",
       "         0.04991991,  0.02340877,  0.0537213 ,  0.08159216,  0.06562652,\n",
       "         0.03199689,  0.05767093,  0.0176915 ,  0.08142924,  0.05097267],\n",
       "       [ 0.14814499,  0.05680781,  0.08295083,  0.24739306,  0.10045778,\n",
       "         0.0837951 ,  0.06683532,  0.09919662,  0.14421508,  1.        ,\n",
       "         0.06766175,  0.02853477,  0.06981129,  0.08909509,  0.09064152,\n",
       "         0.04441646,  0.04415633,  0.03153988,  0.11505792,  0.04285599],\n",
       "       [ 0.04310315,  0.02671721,  0.03124814,  0.03297707,  0.09823007,\n",
       "         0.10636397,  0.14164571,  0.03971094,  0.04991991,  0.06766175,\n",
       "         1.        ,  0.08398076,  0.23088878,  0.20176794,  0.19916795,\n",
       "         0.1170371 ,  0.12241712,  0.02577374,  0.23661623,  0.13518825],\n",
       "       [ 0.02490148,  0.01455872,  0.0166606 ,  0.01682242,  0.04946993,\n",
       "         0.06343312,  0.06963382,  0.0143491 ,  0.02340877,  0.02853477,\n",
       "         0.08398076,  1.        ,  0.10065099,  0.14410523,  0.08915194,\n",
       "         0.0668648 ,  0.06247431,  0.01377666,  0.16590633,  0.07765325],\n",
       "       [ 0.05439486,  0.04785896,  0.03857739,  0.02720506,  0.08848943,\n",
       "         0.1082243 ,  0.14240061,  0.06419564,  0.0537213 ,  0.06981129,\n",
       "         0.23088878,  0.10065099,  1.        ,  0.22685679,  0.2009501 ,\n",
       "         0.12287007,  0.15335076,  0.02981378,  0.30587761,  0.15432643],\n",
       "       [ 0.06889738,  0.06097451,  0.05344801,  0.03217407,  0.15384311,\n",
       "         0.14484943,  0.22188297,  0.05943078,  0.08159216,  0.08909509,\n",
       "         0.20176794,  0.14410523,  0.22685679,  1.        ,  0.23634569,\n",
       "         0.13611662,  0.15424843,  0.12420219,  0.51686077,  0.2611531 ],\n",
       "       [ 0.06388148,  0.03309722,  0.04079396,  0.06347284,  0.10963956,\n",
       "         0.10965567,  0.13441957,  0.05464486,  0.06562652,  0.09064152,\n",
       "         0.19916795,  0.08915194,  0.2009501 ,  0.23634569,  1.        ,\n",
       "         0.13327067,  0.11971808,  0.04555791,  0.28012967,  0.13540385],\n",
       "       [ 0.01877461,  0.01428176,  0.02456069,  0.01942563,  0.06246077,\n",
       "         0.06768116,  0.10049245,  0.03009905,  0.03199689,  0.04441646,\n",
       "         0.1170371 ,  0.0668648 ,  0.12287007,  0.13611662,  0.13327067,\n",
       "         1.        ,  0.07183701,  0.02004369,  0.17373879,  0.08626947],\n",
       "       [ 0.02597555,  0.02627991,  0.01359084,  0.02692955,  0.07112759,\n",
       "         0.08578766,  0.11859024,  0.03833926,  0.05767093,  0.04415633,\n",
       "         0.12241712,  0.06247431,  0.15335076,  0.15424843,  0.11971808,\n",
       "         0.07183701,  1.        ,  0.02220368,  0.20962531,  0.11511982],\n",
       "       [ 0.0219039 ,  0.01108572,  0.01018007,  0.00243989,  0.0358517 ,\n",
       "         0.0151023 ,  0.04866638,  0.01337146,  0.0176915 ,  0.03153988,\n",
       "         0.02577374,  0.01377666,  0.02981378,  0.12420219,  0.04555791,\n",
       "         0.02004369,  0.02220368,  1.        ,  0.07106241,  0.06508542],\n",
       "       [ 0.06752055,  0.06384466,  0.05364983,  0.06743196,  0.15929314,\n",
       "         0.19085106,  0.26657011,  0.07392035,  0.08142924,  0.11505792,\n",
       "         0.23661623,  0.16590633,  0.30587761,  0.51686077,  0.28012967,\n",
       "         0.17373879,  0.20962531,  0.07106241,  1.        ,  0.24985403],\n",
       "       [ 0.03347359,  0.02969764,  0.02882414,  0.02285335,  0.10388119,\n",
       "         0.0773172 ,  0.12357917,  0.03931251,  0.05097267,  0.04285599,\n",
       "         0.13518825,  0.07765325,  0.15432643,  0.2611531 ,  0.13540385,\n",
       "         0.08626947,  0.11511982,  0.06508542,  0.24985403,  1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_approx_train_marcus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ktest_approx-K_approx_test_marcus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
